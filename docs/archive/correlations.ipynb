{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9b5304e",
   "metadata": {},
   "source": [
    "# Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6971ecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "RESULTS_DIR = Path('../../results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c46ee8",
   "metadata": {},
   "source": [
    "## Available Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdad4111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List folders in results directory\n",
    "\n",
    "print(f'Folders in results directory: {[f.name for f in RESULTS_DIR.iterdir() if f.is_dir()]}')\n",
    "# Folders in results directory: ['PhD_Benchmark_results_2023-12-11',\n",
    "# 'PhD_electricity_2023-12-11', 'PhD_electricity_2024-07-19', 'sca']\n",
    "\n",
    "SCA_DIR = RESULTS_DIR / 'sca'\n",
    "print(f'Folders in SCA directory: {[f.name for f in SCA_DIR.iterdir() if f.is_dir()]}')\n",
    "# Folders in SCA directory: ['bandit', 'prospector', 'pylint', 'radon-cc',\n",
    "# 'radon-hal', 'radon-mi', 'radon-raw', 'ruff', 'sonar', 'sonar_parsed', 'SUMMARY']\n",
    "\n",
    "SCA_SUBDIR = SCA_DIR / 'SUMMARY'\n",
    "print(f'Folders in SCA \"SUMMARY\": {[f.name for f in SCA_SUBDIR.iterdir() if f.is_dir()]}')\n",
    "# Folders in SCA \"SUMMARY\": ['correlations', 'csv', 'plots', 'tables', 'tex']\n",
    "\n",
    "ELEC_DIR = RESULTS_DIR / 'PhD_electricity_2024-07-19'\n",
    "print(f'Folders in ELEC directory: {[f.name for f in ELEC_DIR.iterdir() if f.is_dir()]}')\n",
    "# Folders in ELEC directory: ['autots_10800_time_limit', 'autots_7200_time_limit',\n",
    "# 'fedot_10800_time_limit', 'fedot_7200_time_limit', 'nproc_-1', 'original_autots_times',\n",
    "# 'univariate_forecasting', 'univariate_statistics', 'unused']\n",
    "\n",
    "ELEC_SUBDIR = ELEC_DIR / 'univariate_statistics'\n",
    "print(f'ELEC_dir: univariate_statistics: {[f.name for f in ELEC_SUBDIR.iterdir()]}')\n",
    "# ELEC_dir: univariate_statistics: [\n",
    "# '0_autokeras_early_stopping.csv', '0_increased_time_limit.csv', '0_original_autots_times.csv', '0_original_autots_times_comparison.xlsx',\n",
    "# '1_all_scores.csv', '1_all_scores.tex',\n",
    "# '3_failed_counts.png', '3_failed_counts_by_library.png', '3_mean_scores_by_library.csv',\n",
    "# '4_R2_mean_by_library.png',\n",
    "# '5_MAE_box.png', '5_MAE_mean_by_library.png', '5_MSE_box.png',\n",
    "# '6_MSE_mean_by_library.png', '6_RMSE_box.png', '6_Spearman_Correlation_box.png',\n",
    "# '7_duration_mean_by_library.png', '8_duration_box.png',\n",
    "# 'heatmap.csv', 'heatmap.png', 'metrics_corr_heatmap.csv', 'metrics_corr_heatmap.tex',\n",
    "# 'metrics_corr_heatmap_pvalues.csv', 'Pearson Correlation Heatmap.docx', 'Pearson Correlation Heatmap.PNG'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdb0159",
   "metadata": {},
   "source": [
    "## Correlation Analysis Between Forecasting and SCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c967ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV files of SCA data\n",
    "df_sca_all = pd.read_csv(SCA_SUBDIR / 'csv' / 'ranks.csv')\n",
    "print(f'df_sca_all.shape: {df_sca_all.shape}')\n",
    "\n",
    "# Load CSV files of SCA data grouped into categories\n",
    "df_sca_summary = pd.read_csv(SCA_SUBDIR / 'csv' / 'summary_ranks.csv')\n",
    "print(f'df_sca_summary.shape: {df_sca_summary.shape}')\n",
    "\n",
    "# Load CSV files of forecasting results\n",
    "df_forecasting_all = pd.read_csv(ELEC_SUBDIR / '1_all_scores.csv')\n",
    "print(f'df_forecasting_all.shape: {df_forecasting_all.shape}')\n",
    "\n",
    "# Load CSV files of average forecasting scores by library\n",
    "df_forecasting_mean = pd.read_csv(ELEC_SUBDIR / '3_mean_scores_by_library.csv')\n",
    "print(f'df_forecasting_mean.shape: {df_forecasting_mean.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6771fa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sca_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4447fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasting_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5327e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert library to lowercase for merging\n",
    "df_sca_all['library'] = df_sca_all['name'].str.lower()\n",
    "df_sca_all = df_sca_all.drop(columns=['Library', 'name'], errors='ignore')\n",
    "df_forecasting_mean['library'] = df_forecasting_mean['library'].str.lower()\n",
    "\n",
    "# Merge SCA summary with forecasting mean scores on library\n",
    "df_merged = pd.merge(df_sca_all, df_forecasting_mean, on='library')\n",
    "\n",
    "# Set library as index\n",
    "df_merged = df_merged.set_index('library')\n",
    "\n",
    "# Drop columns that are not needed for correlation analysis\n",
    "for col in df_merged.columns:\n",
    "    # We deliberately keep \"_min\" columns due to high correlation with sca metrics\n",
    "    if any(s in col for s in ['Unnamed', 'iterations', 'failed', '_max']) or col in ['Median Rank']:\n",
    "        df_merged = df_merged.drop(columns=[col])\n",
    "\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a3d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap between metrics using Spearman method\n",
    "# to compare model rankings using different metrics\n",
    "corr = df_merged.corr(method='spearman')\n",
    "\n",
    "# Use forecasting metrics as columns\n",
    "corr = corr[[col for col in corr if col in df_forecasting_mean]]\n",
    "\n",
    "# Use SCA metrics as rows\n",
    "corr = corr.loc[[col for col in corr.index if col in df_sca_all]]\n",
    "\n",
    "# Save correlation heatmap to CSV\n",
    "corr.to_csv(RESULTS_DIR / 'metrics_spearman_corr_heatmap.csv')\n",
    "corr.T.to_csv(RESULTS_DIR / 'T_metrics_spearman_corr_heatmap.csv')\n",
    "print(corr.shape)\n",
    "\n",
    "# Hide values between -0.5 and 0.5 for better visualization\n",
    "# corr = corr.mask(abs(corr) < 0.5)\n",
    "\n",
    "plt.figure(figsize=(26, 24))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cbar=False, cmap='coolwarm', square=True, cbar_kws={'shrink': .8})\n",
    "plt.title('Spearman Correlation Heatmap Between SCA Metrics and Forecasting Metrics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1ae447",
   "metadata": {},
   "source": [
    "## Same Correlation Analysis Between SCA and Forecasting Metrics using SCA categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8fd364",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sca_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sca_summary['library'] = df_sca_summary['Library'].str.lower()\n",
    "df_sca_summary = df_sca_summary.drop(columns=['Library', 'name'], errors='ignore')\n",
    "df_forecasting_mean['library'] = df_forecasting_mean['library'].str.lower()\n",
    "\n",
    "# Merge SCA summary with forecasting mean scores on library\n",
    "df_merged = pd.merge(df_sca_summary, df_forecasting_mean, on='library')\n",
    "\n",
    "# Set library as index\n",
    "df_merged = df_merged.set_index('library')\n",
    "\n",
    "# Drop columns that are not needed for correlation analysis\n",
    "for col in df_merged.columns:\n",
    "    # We deliberately keep \"_min\" columns due to high correlation with sca metrics\n",
    "    if any(s in col for s in ['Unnamed', 'iterations', 'failed', '_max']) or col in ['Median Rank']:\n",
    "        df_merged = df_merged.drop(columns=[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5411b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap between metrics using Spearman method\n",
    "# to compare model rankings using different metrics\n",
    "corr = df_merged.corr(method='spearman')\n",
    "\n",
    "# Use forecasting metrics as columns\n",
    "corr = corr[[col for col in corr if col in df_forecasting_mean]]\n",
    "\n",
    "# Use SCA metrics as rows\n",
    "corr = corr.loc[[col for col in corr.index if col in df_sca_summary]]\n",
    "\n",
    "# Save correlation heatmap to CSV\n",
    "corr.to_csv(RESULTS_DIR / 'metrics_spearman_corr_heatmap_shorter.csv')\n",
    "corr.T.to_csv(RESULTS_DIR / 'T_metrics_spearman_corr_heatmap_shorter.csv')\n",
    "print(corr.shape)\n",
    "\n",
    "# Hide values between -0.5 and 0.5 for better visualization\n",
    "# corr = corr.mask(abs(corr) < 0.5)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cbar=False, cmap='coolwarm', square=True, cbar_kws={'shrink': .8})\n",
    "plt.title('Spearman Correlation Heatmap Between Grouped SCA Metrics and Forecasting Metrics')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
